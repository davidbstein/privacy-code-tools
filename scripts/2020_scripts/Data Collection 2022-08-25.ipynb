{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0deb28",
   "metadata": {},
   "source": [
    "# Data Collection and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f265296",
   "metadata": {},
   "source": [
    "To run the script:\n",
    "```\n",
    "pipenv run python manage.py shell_plus --notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5832c5",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    " - Get question sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5a77f",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ecf63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'rest.settings')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9f29b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import re\n",
    "import datetime\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import lru_cache\n",
    "\n",
    "DROPBOX_FOLER = f\"{os.path.expanduser('~')}/Dropbox\"\n",
    "DATA_FOLDER = f\"{DROPBOX_FOLER}/_Law/Documents_and_Adminitrata/_DATA/privacy_coding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "395f26ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_date(ts):\n",
    "    return str(datetime.datetime.fromtimestamp(ts/1000).date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d609dd",
   "metadata": {},
   "source": [
    "# Basic Idea\n",
    "\n",
    "Link all the objects together into macro objects\n",
    "\n",
    "```\n",
    "  Policy -> list<PolicyInstance>\n",
    "  Policy -> list<Question>\n",
    "      Question -> list<Answer>\n",
    "      Answer -> CodingInstance, Coder, ect...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d8ea4",
   "metadata": {},
   "source": [
    "## Connectors\n",
    "\n",
    "`connect` maps parents to children, and visa versa:\n",
    "```\n",
    "    Parent -> list<Child>\n",
    "    Child -> Parent\n",
    "```\n",
    "\n",
    "There's weird magic for timing session because it only has a coding instance id, so I need to follow up to grandparents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e138f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['policyinstance', 'coding', 'timingsession', 'codinginstance', 'policy'])\n",
      "dict_keys(['policyinstance', 'coding', 'timingsession', 'codinginstance', 'policy'])\n"
     ]
    }
   ],
   "source": [
    "def load_json_folder(path):\n",
    "    to_ret = {}\n",
    "    to_skip = [f\"api_{fn}.json\" for fn in \"coder project kvstore assignmenttype assignment\".split()]\n",
    "    for fname in os.listdir(path):\n",
    "        if not fname.endswith(\".json\") or (fname in to_skip):\n",
    "            continue\n",
    "        with open(f\"{path}/{fname}\") as f:\n",
    "            to_ret[fname[len(\"api_\"):-len(\".json\")]] = json.load(f)\n",
    "    return to_ret\n",
    "\n",
    "def to_dicts(dataset, emails_to_remove):\n",
    "    to_ret = {}\n",
    "    for table, raw_data in dataset.items():\n",
    "        to_ret[table] = {\n",
    "            e['id']: expand_object_json(e)\n",
    "            for e in raw_data \n",
    "            if (\n",
    "                e.get(\"coder_email\", \"\") not in emails_to_remove\n",
    "                and e.get(\"project\", 1) == 1\n",
    "            )\n",
    "        }\n",
    "    return to_ret\n",
    "\n",
    "def expand_object_json(e):\n",
    "    for k, v in e.items():\n",
    "        if type(v) == str and k != \"coder_email\":\n",
    "            try:\n",
    "                e[k] = json.loads(v)\n",
    "            except:\n",
    "                pass\n",
    "    return e\n",
    "\n",
    "BAD_EMAILS = [\"davidbstein@gmail.com\", \"dbs438@nyu.edu\", \"emily.a.moberg@gmail.com\"]\n",
    "_data_1 = load_json_folder(f\"{DATA_FOLDER}/RAW_DATA/privacycoding.com\")\n",
    "_data_2 = load_json_folder(f\"{DATA_FOLDER}/RAW_DATA/documentcoding.com\")\n",
    "d1 = to_dicts(_data_1, BAD_EMAILS)\n",
    "d2 = to_dicts(_data_2, BAD_EMAILS)\n",
    "print(d1.keys())\n",
    "print(d2.keys())\n",
    "\n",
    "def connect(dataset, parent_name, child_name):\n",
    "    \"\"\"\n",
    "    for all parents and children, add object references in both directions.\n",
    "    \"\"\"\n",
    "    parent_id_key = f\"{parent_name}_id\"\n",
    "    parent_ref_key = f\"{parent_name}\"\n",
    "    child_ref_key = f\"{child_name}\"\n",
    "    children = dataset[child_name.replace(\"_\", \"\")]\n",
    "    parents = dataset[parent_name.replace(\"_\", \"\")]\n",
    "    for child in children.values():\n",
    "        parent_id = child.get(parent_id_key)\n",
    "        parent = parents.get(parent_id)\n",
    "        child[parent_ref_key] = parent\n",
    "        if parent:\n",
    "            if parent.get(child_ref_key):\n",
    "                parent[child_ref_key].append(child)\n",
    "            else:\n",
    "                parent[child_ref_key] = [child]\n",
    "\n",
    "def augment_timing_sessions(d, default_coding):\n",
    "    \"\"\"\n",
    "    adds a `coding_instance_id` to each timing session.\n",
    "     - determines coding instance using c_id, pi_id, and email.\n",
    "    \"\"\"\n",
    "    c_pi_tuple2ci = {\n",
    "        (ci['coding_id'], ci['policy_instance_id'], ci['coder_email']): ci\n",
    "        for ci in d['codinginstance'].values()\n",
    "    }\n",
    "    problem_count = 0\n",
    "    for t_sess in d['timingsession'].values():\n",
    "        key = (t_sess['coding_id'], t_sess['policy_instance_id'], t_sess['coder_email'])\n",
    "        altkey = (default_coding, *key[1:])\n",
    "        if key not in c_pi_tuple2ci:\n",
    "            if altkey in c_pi_tuple2ci:\n",
    "                key=altkey\n",
    "            else:\n",
    "                c = d['coding'].get(key[0])\n",
    "                pi = d['policyinstance'].get(key[1])\n",
    "                info = [t_sess['id'], key, len(t_sess['question_timings']), c is None, pi is None]\n",
    "                if not t_sess['question_timings']:\n",
    "                    #print(f\"PROBLEM:{info}\")\n",
    "                    problem_count+=1\n",
    "                else:\n",
    "                    #print(info)\n",
    "                    pass\n",
    "                continue\n",
    "        assert c_pi_tuple2ci[key]['coder_email'] == t_sess['coder_email'], \\\n",
    "            f\"DOESNT MATCH: {t_sess['id']}{key} {c_pi_tuple2ci[key]['coder_email']} {t_sess['coder_email']}\"\n",
    "        t_sess['coding_instance_id'] = c_pi_tuple2ci[key]['id']\n",
    "    print(f\"{problem_count}/{len(d['timingsession'])} problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ccc7b2",
   "metadata": {},
   "source": [
    "## RUNNER: Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f67a83c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENTCODING\n",
      "0/139 problems\n",
      "PRIVACYCODING\n",
      "89/1969 problems\n"
     ]
    }
   ],
   "source": [
    "def do_connections(d, default_coding):\n",
    "    connect(d, 'policy', 'policy_instance')\n",
    "    connect(d, 'policy_instance', 'coding_instance')\n",
    "    connect(d, 'coding', 'coding_instance')\n",
    "    augment_timing_sessions(d, default_coding)\n",
    "    connect(d, 'coding_instance', 'timing_session')\n",
    "\n",
    "print(\"DOCUMENTCODING\")\n",
    "do_connections(d1, 6)\n",
    "\n",
    "print(\"PRIVACYCODING\")\n",
    "do_connections(d2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00d891",
   "metadata": {},
   "source": [
    "### Lookup Tables\n",
    "\n",
    "Question lookups:\n",
    "```\n",
    "    [year, c_id, q_id]: {\n",
    "        category, type, option, info\n",
    "    }\n",
    "    \n",
    "    lookup_question(year, c_id, q_id)  -> Question\n",
    "    lookup_all_question_versions(q_id) -> list<Question>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b6eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_question_lookup_dict(d, year):\n",
    "    \"\"\"\n",
    "    creates a dict of questions:\n",
    "        [year, c_id, q_id]: {\n",
    "            category, type, option, info\n",
    "        }\n",
    "    \"\"\"\n",
    "    to_ret = dict()\n",
    "    for c_id, coding in d['coding'].items():\n",
    "        if 'categories' in coding:\n",
    "            id_key = \"id\"\n",
    "            cats = coding['categories']\n",
    "        else:\n",
    "            id_key = \"identifier\"\n",
    "            cats = [{\"label\": None, \"questions\": coding['questions']}]\n",
    "        for cat in cats:\n",
    "            for question in cat['questions']:\n",
    "                if id_key not in question:\n",
    "                    continue\n",
    "                if \"questionOptions\" in question:\n",
    "                    options = {\n",
    "                        o['value']: o['label'] \n",
    "                        for o in question['questionOptions']\n",
    "                    }\n",
    "                elif \"values\" in question:\n",
    "                    if question['values'] and type(question['values'][0]) == str:\n",
    "                        options = {\n",
    "                            o: None\n",
    "                            for o in question['values']\n",
    "                        }\n",
    "                    else:\n",
    "                        options = {\n",
    "                            o['value']: o['label'] \n",
    "                            for o in question['values']\n",
    "                        }\n",
    "                else:\n",
    "                    print(question.keys())\n",
    "                type_ = question['type']\n",
    "                if type(type_) != str:\n",
    "                    type_ = type_['value']\n",
    "                to_ret[(year, c_id, question[id_key])] = {\n",
    "                    \"category\": cat['label'],\n",
    "                    \"type\": type_,\n",
    "                    \"options\": options,\n",
    "                    \"info\": question.get(\"info\")\n",
    "                }\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd31f50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_question_lookups = {}\n",
    "_question_lookups.update(build_question_lookup_dict(d1, \"2021\"))\n",
    "_question_lookups.update(build_question_lookup_dict(d2, \"2020\"))\n",
    "def lookup_all_question_versions(q_id):\n",
    "    return [q for k, q in _question_lookups.items() if k[2] == q_id]\n",
    "\n",
    "def lookup_question(year, c_id, q_id, suppress_options=False):\n",
    "    for possible_coding_id in range(c_id, 0, -1):\n",
    "        key = (year, possible_coding_id, q_id)\n",
    "        if key in _question_lookups:\n",
    "            return {\n",
    "                k: v \n",
    "                for k, v in _question_lookups[key].items() \n",
    "                if not suppress_options or k != \"options\"\n",
    "            }\n",
    "\n",
    "def question_id_sort_fn(q_id):\n",
    "    re_number = \"(\\d+(?:\\.\\d+)?)\"\n",
    "    re_year = \"(\\d\\d\\d\\d)\"\n",
    "    if q_id == \"PP_in_TOU\":\n",
    "        q_id = \"v999_2021\"\n",
    "    found = re.findall(f\"v_?{re_number}(.*)_{re_year}\", q_id)\n",
    "    num, _, year = found[0]\n",
    "    return year, float(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82626f20",
   "metadata": {},
   "source": [
    " - Policy\n",
    "     - scrape_date\n",
    "     - id\n",
    "     - info `{company_name, site_name}`\n",
    "     - questions `{question_id: list(<answer>)}`\n",
    " - Answer\n",
    "     - values\n",
    "     - confidence\n",
    "     - comments\n",
    "     - timing_focus\n",
    "     - timing_blur\n",
    "     - coder_email\n",
    "     - coding_id\n",
    "     - date\n",
    "     - question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "016de047",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for testing\n",
    "def get_sample_pol(d):\n",
    "    for p_id, p in d['policy'].items():\n",
    "        pi_list = p.get(\"policy_instance\", [])\n",
    "        for pi in pi_list:\n",
    "            ci_list = pi.get(\"coding_instance\", [])\n",
    "            for ci in ci_list:\n",
    "                return p\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b90ed3",
   "metadata": {},
   "source": [
    "## Cleaning phase 1:\n",
    "\n",
    "Now that database objects are linked, normalize policy objects and map `Policy -> list<AnswerInstance>`\n",
    "\n",
    "AnswerInstances are based on question id, and not grouped by coding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cce3bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_questions_from_ci(ci, year):\n",
    "    \"\"\"\n",
    "    returns a dict of questions, with a sum of all timing records\n",
    "    {\n",
    "        <q_id>: AnswerInstance\n",
    "    }\n",
    "    \"\"\"\n",
    "    to_ret = {}\n",
    "    for question_id, q in ci['coding_values'].items():\n",
    "        if not q or not (question_id.startswith(\"v\") or question_id == \"PP_in_TOU\"):\n",
    "            continue\n",
    "        # NEW: remove redundancy\n",
    "        timing_focus, timing_blur = None, None\n",
    "        coding_date = ci['created_dt'].split(\" \")[0]\n",
    "        if ci.get('timing_session'):\n",
    "            timing_focus, timing_blur = 0, 0\n",
    "        for t_sess in ci.get('timing_session', []):\n",
    "            for q_id, t_record in t_sess['question_timings'].items():\n",
    "                if q_id == question_id:\n",
    "                    timing_blur += t_record['total_blur']/1000\n",
    "                    timing_focus += t_record['total_focus']/1000\n",
    "                    coding_date = ts_to_date(t_record['start_ts'])\n",
    "        to_ret[question_id] = {\n",
    "            \"values\": [k for k, v in q['values'].items() if v],\n",
    "            \"confidence\": q['confidence'],\n",
    "            \"comments\": q.get(\"comment\"),\n",
    "            \"timing_focus\": timing_blur,\n",
    "            \"timing_blur\": timing_focus,\n",
    "            \"coder_email\": ci['coder_email'],\n",
    "            \"coding_id\": f\"{year}-{ci['coding']['id']}\",\n",
    "            \"date\": coding_date,\n",
    "            \"question\": lookup_question(year, ci['coding']['id'], question_id, suppress_options=True),\n",
    "            \n",
    "            # \"sentences\"\n",
    "        }\n",
    "    return to_ret\n",
    "\n",
    "def clean_policy(p, year, info_keys):\n",
    "    \"\"\"\n",
    "    for each policy, returns:\n",
    "    {\n",
    "        info: {<info_key>: value}\n",
    "        questions: {<q_id>: list<Answer>}\n",
    "    }\n",
    "    \n",
    "    Only picks one answer per coder\n",
    "    \"\"\"\n",
    "    to_ret = {}\n",
    "    to_ret['info'] = {k: p[k] for k in info_keys}\n",
    "    pi_list = p.get(\"policy_instance\", [])\n",
    "    question_dict = defaultdict(list)\n",
    "    to_ret['questions'] = {}\n",
    "    for pi in pi_list:\n",
    "        ci_list = pi.get(\"coding_instance\", [])\n",
    "        for ci in ci_list:\n",
    "            for question_id, question in get_questions_from_ci(ci, year).items():\n",
    "                question_dict[question_id].append(question)\n",
    "        for question_id, ans_list in question_dict.items():\n",
    "            to_ret['questions'][question_id] = ans_list\n",
    "    return to_ret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24b0d8",
   "metadata": {},
   "source": [
    "## cleaning phase 2:\n",
    "\n",
    "Remove any instances of multiple answers to the same question from the same coder.\n",
    "\n",
    "Merge sites coded in both 2020 and 2021\n",
    "\n",
    "\n",
    "__NOTE__ SKETCHY SORTING FOR PICKING BEST ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9f44ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_double_vote_answers(answer_list):\n",
    "    return {\n",
    "        ans['coder_email']: ans \n",
    "        for ans in sorted(answer_list, key=lambda q:q['date'])\n",
    "    }.values()\n",
    "\n",
    "\n",
    "def merge_pols(p_list):\n",
    "    \"\"\"\n",
    "    Merge a list of policies that correspond to the same site.\n",
    "    \n",
    "     - overwrites info entries\n",
    "     - extends repeat question instances {<q_id>: list<AnswerInstance>}\n",
    "    \n",
    "    \"\"\"\n",
    "    to_ret = {}\n",
    "    to_ret['info']={}\n",
    "    to_ret['questions'] = defaultdict(list)\n",
    "    for p in p_list:\n",
    "        to_ret['info'].update(p['info'])\n",
    "        for q_id, q in p['questions'].items():\n",
    "            to_ret['questions'][q_id].extend(q)\n",
    "    for q_id, answer_list in to_ret['questions'].items():\n",
    "        to_ret['questions'][q_id] = filter_double_vote_answers(answer_list)\n",
    "    return to_ret\n",
    "\n",
    "\n",
    "def get_cleaned_policies(d1, d2):\n",
    "    \"\"\"\n",
    "    returns a dict of cleaned policy lists:\n",
    "    {\n",
    "        <Policy.site_name>: list<CleanPolicy>\n",
    "    }\n",
    "    \"\"\"\n",
    "    d1_info_keys = [\"company_name\", \"site_name\", \"categories\"]\n",
    "    d2_info_keys = [\"company_name\", \"site_name\"]\n",
    "    cleaned_pols = defaultdict(list)\n",
    "    for p in d2['policy'].values():\n",
    "        cp = clean_policy(p, '2020', d2_info_keys)\n",
    "        cleaned_pols[cp['info']['site_name']].append(cp)\n",
    "    for p in d1['policy'].values():\n",
    "        cp = clean_policy(p, '2021', d1_info_keys)\n",
    "        cleaned_pols[cp['info']['site_name']].append(cp)\n",
    "    return [\n",
    "        merge_pols(p_list)\n",
    "        for p_list in cleaned_pols.values()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e6fbe1",
   "metadata": {},
   "source": [
    "## Cleaning Step 3\n",
    "\n",
    "Remove any questions with less than 2 answers.\n",
    "\n",
    "Remove any policies that aren't mostly coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "ba6efd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINAL_QUESTION_IDS = []\n",
    "for cat in d1['coding'][6]['categories']:\n",
    "    if \"Skip me\" in cat['label']:\n",
    "        continue\n",
    "    for q in cat['questions']:\n",
    "        FINAL_QUESTION_IDS.append(q['id'])\n",
    "len(FINAL_QUESTION_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "319ea5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worth_keeping(cp):\n",
    "    return len(cp['questions'])>50\n",
    "\n",
    "def clean_questions(cp):\n",
    "    to_ret = {k:v for k, v in cp.items()}\n",
    "    to_ret['questions'] = {\n",
    "        q_id: question for q_id, question in cp['questions'].items()\n",
    "        if len([answer for answer in question if True]) >= 2\n",
    "        and q_id in FINAL_QUESTION_IDS\n",
    "    }\n",
    "    return to_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "09dc8790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pols = get_cleaned_policies(d1, d2)\n",
    "\n",
    "CODED_POLICIES = [\n",
    "    cp for cp in \n",
    "    map(clean_questions, clean_pols) \n",
    "    if worth_keeping(cp)\n",
    "]\n",
    "len(CODED_POLICIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "383ac1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TIMED_ANSWERS = []\n",
    "ALL_ANSWERS = []\n",
    "for pol in CODED_POLICIES:\n",
    "    for q_id, answers in pol['questions'].items():\n",
    "        for answer in answers:\n",
    "            to_add = {\"policy\": pol['info']['site_name'], \"question_id\": q_id}\n",
    "            to_add.update(answer)\n",
    "            ALL_ANSWERS.append(to_add)\n",
    "            if answer['timing_focus']:\n",
    "                ALL_TIMED_ANSWERS.append(to_add)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d38ead",
   "metadata": {},
   "source": [
    "# organizational scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "56c71308",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def summarize_cleaned_pols(pol_list):\n",
    "    print(''.join(\n",
    "        f\"\\n{count:>3}. {pol['info']['site_name']+' ':_<30} {len(pol['questions'].keys())}\"\n",
    "         for count, pol in enumerate(sorted(pol_list, key=lambda p: len(p['questions'].keys())))\n",
    "    ))\n",
    "\n",
    "def summarize_cleaned_pol(pol):\n",
    "    print(f\"{pol['info']['site_name']+' ':_<30} {len(pol['questions'].keys())}\")\n",
    "    print(''.join(sorted((f\"{k:<31}\" for k, v in pol['questions'].items()), \n",
    "                          key=question_id_sort_fn)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "423012f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FMW_EMAIL = \"florencia.m.wurgler@gmail.com\"\n",
    "NON_MATCH_KEY = \"unresolved non-matching responses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e5e24b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _coders_match(answers):\n",
    "    return len(set(tuple(a['values']) \n",
    "            for a in answers \n",
    "            if a['values'] and a['coder_email'] != FMW_EMAIL\n",
    "    )) == 1\n",
    "\n",
    "def resolve_answer(answer_list_for_question):\n",
    "    answers = {answer['coder_email']: answer for answer in answer_list_for_question}\n",
    "    if FMW_EMAIL in answers:\n",
    "        return ','.join(answers[\"florencia.m.wurgler@gmail.com\"]['values'])\n",
    "    else:\n",
    "        # This is a broken BODGE\n",
    "        if _coders_match(answer_list_for_question):\n",
    "            return ','.join(list(answers.values())[0]['values'])\n",
    "        else:\n",
    "#             print(answers)\n",
    "            return NON_MATCH_KEY\n",
    "        \n",
    "def resolve_agreement(answer_list_for_question):\n",
    "    answers = {answer['coder_email']: answer for answer in answer_list_for_question}\n",
    "    if _coders_match(answer_list_for_question) and FMW_EMAIL in answers:\n",
    "        return \"reviewer_override\"\n",
    "    if _coders_match(answer_list_for_question):\n",
    "        return \"full_agreement\"\n",
    "    if not _coders_match(answer_list_for_question):\n",
    "        return \"disagreement\"\n",
    "\n",
    "def agreement_label(answer_list_for_question):\n",
    "    answers = {answer['coder_email']: answer for answer in answer_list_for_question}\n",
    "    if \"florencia.m.wurgler@gmail.com\" in answers:\n",
    "            return 1\n",
    "        \n",
    "def make_row(pol, resolver):\n",
    "    question_row = [[q_id, resolve_answer(q)] for q_id, q in pol['questions'].items()]\n",
    "    return dict(\n",
    "        company_name=pol['info']['site_name'],        \n",
    "        **dict(question_row)\n",
    "    )\n",
    "\n",
    "def save_answer_csv(policy_list, resolver, filename):\n",
    "    all_rows = [make_row(p, resolver) for p in policy_list]\n",
    "    fieldnames = sorted(set([i for i in sum(\n",
    "        (list(r.keys()) for r in all_rows)\n",
    "        , [])]))\n",
    "    with open(f\"{DATA_FOLDER}/CSVs/{filename}.csv\", 'w') as f:\n",
    "        writer=csv.DictWriter(f, fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_rows)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "956bca86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_answer_csv(CODED_POLICIES, resolve_answer, \"coding_values\")\n",
    "save_answer_csv(CODED_POLICIES, resolve_agreement, \"agreement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1f7e13",
   "metadata": {},
   "source": [
    "# Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "89a7a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textchart import textchart\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b8583",
   "metadata": {},
   "source": [
    "Helper functions\n",
    "```python\n",
    "lookup_all_question_versions(question_id)\n",
    "lookup_policy(site_name)\n",
    "resolve_answer(policy['questions'][q_id])\n",
    "\n",
    "CODED_POLICIES\n",
    "ALL_TIMED_ANSWERS\n",
    "ALL_ANSWERS\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4b200ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"policy\": \"match.com\",\n",
      " \"question_id\": \"v17_2020\",\n",
      " \"values\": [\n",
      "  \"DND\"\n",
      " ],\n",
      " \"confidence\": \"4\",\n",
      " \"comments\": \"\",\n",
      " \"timing_focus\": 95679.711,\n",
      " \"timing_blur\": 74.386,\n",
      " \"coder_email\": \"msr634@nyu.edu\",\n",
      " \"coding_id\": \"2020-6\",\n",
      " \"date\": \"2020-07-11\",\n",
      " \"question\": {\n",
      "  \"category\": null,\n",
      "  \"type\": \"singleselect\",\n",
      "  \"info\": \"Third party tracking: site allows third parties to place advertisements that may track user behavior?\"\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(ALL_TIMED_ANSWERS[0], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "cb70497e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"values\": [\n",
      "      \"1\"\n",
      "    ],\n",
      "    \"confidence\": \"4\",\n",
      "    \"comments\": \"\",\n",
      "    \"timing_focus\": 0,\n",
      "    \"timing_blur\": 0,\n",
      "    \"coder_email\": \"msr634@nyu.edu\",\n",
      "    \"coding_id\": \"2020-10\",\n",
      "    \"date\": \"2020-07-09\",\n",
      "    \"question\": {\n",
      "      \"category\": null,\n",
      "      \"type\": \"singleselect\",\n",
      "      \"info\": \"Is the CCPA section in a separate link (as opposed to in the same privacy policy?)\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"values\": [\n",
      "      \"0\"\n",
      "    ],\n",
      "    \"confidence\": \"5\",\n",
      "    \"comments\": \"\",\n",
      "    \"timing_focus\": 0,\n",
      "    \"timing_blur\": 0,\n",
      "    \"coder_email\": \"ns4649@nyu.edu\",\n",
      "    \"coding_id\": \"2020-10\",\n",
      "    \"date\": \"2020-07-29\",\n",
      "    \"question\": {\n",
      "      \"category\": null,\n",
      "      \"type\": \"singleselect\",\n",
      "      \"info\": \"Is the CCPA section in a separate link (as opposed to in the same privacy policy?)\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "for p in CODED_POLICIES: \n",
    "    print(json.dumps(list(p['questions'][FINAL_QUESTION_IDS[0]]), indent=2))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc672876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c010685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responses_for_question(q_id, timed_only=True):\n",
    "    answer_list = ALL_TIMED_ANSWERS if timed_only else ALL_ANSWERS\n",
    "    answer_dict = defaultdict(list) \n",
    "    for a in answer_list:\n",
    "        if a['question_id'] == q_id:\n",
    "            answer_dict[(a['coder_email'], a['policy'])].append(a)\n",
    "    return [sorted(a, key=lambda e: e['date'])[-1] for a in answer_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "09ed705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers_for_question(q_id, timed_only=False):\n",
    "    answer_list = ALL_TIMED_ANSWERS if timed_only else ALL_ANSWERS\n",
    "    answer_dict = defaultdict(list) \n",
    "    for a in answer_list:\n",
    "        if a['question_id'] == q_id:\n",
    "            answer_dict[(a['policy'])].append(a)\n",
    "    return [sorted(a, key=lambda e: e['date']) for a in answer_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a173f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_clusters_for_question(q_id):\n",
    "    answer_list = ALL_ANSWERS\n",
    "    answer_dict = defaultdict(list) \n",
    "    for a in answer_list:\n",
    "        if a['question_id'] == q_id:\n",
    "            answer_dict[(a['policy'])].append(a)\n",
    "    return [sorted(a, key=lambda e: e['date']) for a in answer_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "74bf4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNRECONSILED = \"UNRECONSILED\"\n",
    "CONFIDENCES = ['', \"1: lowest\", \"2: low\", \"3: moderate\", \"4: high\", \"5: highest\"]\n",
    "def response_cluster_to_answer_info(responses):\n",
    "    coder_responses = [r for r in responses if r['coder_email'].endswith(\"@nyu.edu\")]\n",
    "    grader_responses = [r for r in responses if not r['coder_email'].endswith(\"@nyu.edu\")]\n",
    "    assert len(grader_responses) <= 1\n",
    "    coder_response_set = [' & '.join(sorted(resp['values'])) for resp in coder_responses]\n",
    "    all_response_set = [' & '.join(sorted(resp['values'])) for resp in responses]\n",
    "    coders_agree = len(set(coder_response_set)) == 1\n",
    "    grader_overrules = coders_agree and len(set(all_response_set)) != 1\n",
    "    agreement = \"\"\n",
    "    if grader_responses:\n",
    "        answer = \" & \".join(grader_responses[0]['values'])\n",
    "    elif coders_agree:\n",
    "        answer = \" & \".join(coder_responses[0]['values'])\n",
    "    else:\n",
    "        answer = UNRECONSILED\n",
    "    if coders_agree:\n",
    "        agreement = \"coders agree\"\n",
    "    elif coders_agree and len(set(all_response_set)) != 1:\n",
    "        agreement = \"coders agree, all incorrect\"\n",
    "    elif answer == UNRECONSILED:\n",
    "        agreement = \"unreconsiled disagreement\"\n",
    "    elif not coders_agree and len(set(coder_response_set)) == len(set(all_response_set)):\n",
    "        agreement = \"coders disagree, ≥1 coder match grader\"\n",
    "    elif not coders_agree and len(set(coder_response_set)) == len(set(all_response_set)):\n",
    "        agreement = \"coders disagree, 0 coders match grader\"\n",
    "    confidences = [int(resp[\"confidence\"]) for resp in coder_responses if resp.get(\"confidence\")]\n",
    "    return {\n",
    "        \"num_coders\": len(coder_response_set),\n",
    "        \"coders_agree\": coders_agree,\n",
    "        \"grader_overruled\": grader_overrules,\n",
    "        \"agreement\": agreement,\n",
    "        \"answer\": answer,\n",
    "        \"avg_confidence\": \"not reported\" if not confidences else f\"{round(2*sum(confidences) / len(confidences))/2:0.1f}\",\n",
    "        \"low_confidence\": \"not reported\" if not confidences else CONFIDENCES[list(sorted(confidences))[0]],\n",
    "        \"high_confidence\": \"not reported\" if not confidences else CONFIDENCES[list(sorted(confidences))[-1]],\n",
    "        \"confidences\": confidences,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6fcda50a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_inner_width = 85\n",
    "_outer_width = 90\n",
    "\n",
    "def cluster_stat(key=\"answer\"):\n",
    "    def inner(q_id):\n",
    "        clusters = response_clusters_for_question(q_id)\n",
    "        answer_infos = list(map(response_cluster_to_answer_info, clusters))\n",
    "        return dict(Counter([info[key] for info in answer_infos]))\n",
    "    return inner\n",
    "\n",
    "def confidences(q_id):\n",
    "    clusters = response_clusters_for_question(q_id)\n",
    "    answer_infos = list(map(response_cluster_to_answer_info, clusters))\n",
    "    confidences = sum([info[\"confidences\"] for info in answer_infos], [])\n",
    "    return dict(Counter(confidences))\n",
    "\n",
    "def variance_sorter(fn):\n",
    "    def inner(q_id):\n",
    "        vals = sorted(fn(q_id).values())\n",
    "        if len(vals) >= 2:\n",
    "            a, b = vals[-2:]\n",
    "        else:\n",
    "            a, b = 1, 1\n",
    "        return a/b\n",
    "    return inner\n",
    "\n",
    "def draw_stat(fn, name):\n",
    "    with open(f\"{DATA_FOLDER}/2022-09-11_{name}.txt\", \"w\") as f:\n",
    "        for cat in d1['coding'][6]['categories']:\n",
    "            if \"Skip me\" in cat['label']:\n",
    "                continue\n",
    "            entry = []\n",
    "            entry.append(textchart.add_border(cat['label'], max_width=_inner_width))\n",
    "#             print(json.dumps(cat, indent=2))\n",
    "            for q in sorted(cat['questions'], key=variance_sorter(fn)):\n",
    "                q_id = q['id']\n",
    "                question = summarize_question(q_id)['question']\n",
    "                counts = fn(q_id)\n",
    "                unreconsiled = counts.get(UNRECONSILED)\n",
    "                q_entry = [\n",
    "                    question['info'],\n",
    "                    textchart.bar_graph({k:v for k,v in counts.items() if k!=UNRECONSILED}),\n",
    "                ]\n",
    "                if unreconsiled:\n",
    "                    q_entry.append(f\"{f'({unreconsiled} unreconsiled disagreements)':>{_inner_width-2}}\")\n",
    "                entry.append(textchart.add_border(\"\\n\".join(q_entry), max_width=_inner_width))\n",
    "            f.write(textchart.add_border('\\n'.join(entry), max_width=_outer_width, bold=True))\n",
    "            f.write(\"\\n\"*5)\n",
    "draw_stat(cluster_stat(\"answer\"), \"policy_breakdown\")\n",
    "draw_stat(cluster_stat(\"agreement\"), \"agreement\")\n",
    "draw_stat(cluster_stat(\"avg_confidence\"), \"self_reported_confidence\")\n",
    "draw_stat(confidences, \"self_reported_confidence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "792177e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_table(array):\n",
    "    col_widths = []\n",
    "    for row in array:\n",
    "        for i, col in enumerate(row):\n",
    "            if len(col_widths) <= i:\n",
    "                col_widths.append(0)\n",
    "            col_widths[i] = max(col_widths[i], len(str(col)))\n",
    "    to_ret = []\n",
    "    spacer = [\"\\n\"] + [f\"├─{'':─^{width}}─\" for width in col_widths] + [\"─┤\"]\n",
    "    for row in array:\n",
    "        to_ret.extend(spacer)\n",
    "        to_ret.append(\"\\n\")\n",
    "        to_ret.extend([f\"│ {col:>{width}} \" for width, col in zip(col_widths, row)])\n",
    "        to_ret.append(\" │\")\n",
    "    to_ret.extend(spacer)\n",
    "    return ''.join(to_ret)\n",
    "\n",
    "def format_lookup_table(my_dict, row_keys=None, col_keys=None):\n",
    "    row_keys = row_keys or sorted(set([k[0] for k in my_dict]))\n",
    "    col_keys = col_keys or sorted(set([k[1] for k in my_dict]))\n",
    "    return format_table(\n",
    "        [[''] + [(col) for col in col_keys]] + \n",
    "        [\n",
    "        [(row)] + [my_dict.get((row, col), '') for col in col_keys] \n",
    "        for row in row_keys\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7817544d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def cluster_stat_comparison(k1=\"low_confidence\", k2=\"high_confidence\"):\n",
    "    def inner(q_id):\n",
    "        clusters = response_clusters_for_question(q_id)\n",
    "        answer_infos = list(map(response_cluster_to_answer_info, clusters))\n",
    "        return dict(Counter([(info[k1], info[k2]) for info in answer_infos]))\n",
    "    return inner\n",
    "\n",
    "\n",
    "def draw_table(fn, name, row_keys=None, col_keys=None):\n",
    "    with open(f\"{DATA_FOLDER}/2022-09-11_{name}.txt\", \"w\") as f:\n",
    "        for cat in d1['coding'][6]['categories']:\n",
    "            if \"Skip me\" in cat['label']:\n",
    "                continue\n",
    "            entry = []\n",
    "            entry.append(textchart.add_border(cat['label'], max_width=_inner_width))\n",
    "#             print(json.dumps(cat, indent=2))\n",
    "            for q in sorted(cat['questions'], key=variance_sorter(fn)):\n",
    "                q_id = q['id']\n",
    "                question = summarize_question(q_id)['question']\n",
    "                data = fn(q_id)\n",
    "                q_entry = [\n",
    "                    question['info'],\n",
    "                    format_lookup_table(data, row_keys=row_keys, col_keys=col_keys),\n",
    "                ]\n",
    "                entry.append(textchart.add_border(\"\\n\".join(q_entry), max_width=_inner_width))\n",
    "            f.write(textchart.add_border('\\n'.join(entry), max_width=_outer_width, bold=True))\n",
    "            f.write(\"\\n\"*5)\n",
    "\n",
    "draw_table(cluster_stat_comparison(), \"self-reported-confidence_pairs\", row_keys=CONFIDENCES[1:], col_keys=CONFIDENCES[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "3803ea84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': None,\n",
       " 'type': 'singleselect',\n",
       " 'options': {'0': \"[ 0 ] no, it's part of the same privacy policy\",\n",
       "  '1': \"[ 1 ] yes, it's on a separate link or separate document\",\n",
       "  '.': '[ . ] N/A -there is no CCPA section or CCPA reference in the contract'},\n",
       " 'info': 'Is the CCPA section in a separate link (as opposed to in the same privacy policy?)'}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_question('v72.1_2020.1')['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "dee0d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_question(q_id):\n",
    "    final_answers = defaultdict(int)\n",
    "    for policy in CODED_POLICIES:\n",
    "        answers = policy['questions'].get(q_id)\n",
    "        if answers:\n",
    "            resolved = resolve_answer(answers)\n",
    "            if resolved:\n",
    "                final_answers[resolved] += 1\n",
    "    a_list, q_list = question_data(q_id)\n",
    "    return dict(\n",
    "        question=q_list[-1],\n",
    "        final_answers=final_answers,\n",
    "        agreement_frequency=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "9caf9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWLINE = \"\\n\"\n",
    "def render_answer_frequency(answer_counts, all_answers):\n",
    "    max_val = max(answer_counts.values())\n",
    "    to_show = [(v.replace(',', ' & '), c) for v, c in sorted(answer_counts.items()) if v != NON_MATCH_KEY]\n",
    "    gap = max([20] + [len(str(v)) for v, _ in to_show])\n",
    "    to_ret = [\n",
    "f\"\"\"{textchart.add_border('Coding Summary', fit=True)}\n",
    "policies with question fully coded: {sum(answer_counts.values())}\n",
    "answers recorded: {len(all_answers)}\n",
    "\n",
    "{answer_counts[NON_MATCH_KEY]} unresolved, non-matching responses!\"\"\"]\n",
    "    for val, count in to_show:\n",
    "        to_ret.append(f\"{val:>{gap}}: {'':■>{40*count/max_val}} {count}\")\n",
    "    return textchart.add_border('\\n'.join(to_ret), max_width=83)\n",
    "\n",
    "def render_summary():\n",
    "    return textchart.add_border(f\"\"\"\n",
    "Fully Coded Policies: {len(CODED_POLICIES)}\n",
    "Recorded Answers: {len(ALL_ANSWERS)}\n",
    "Recorded Answers with Timing: {len(ALL_TIMED_ANSWERS)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "bbebd1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing_summary(timed_answers):\n",
    "    if not timed_answers:\n",
    "        return \"(insufficient timing data)\"\n",
    "    timings = [(a['timing_focus'], a['timing_blur']) for a in sum(timed_answers, [])]\n",
    "    if len(timings) > 1:\n",
    "        chart = textchart.scatterplot(\n",
    "            timings, \n",
    "            x_range=[0, max([t[0] for t in timings])],\n",
    "            y_range=[0, max([t[1] for t in timings])],\n",
    "            x_scale_fn=textchart.SCALE_FN.log, \n",
    "            y_scale_fn=textchart.SCALE_FN.log,\n",
    "            x_label=f\"time spent answering question\\n (secs) (log scale)\",\n",
    "            y_label=f\"extra time\\nspent (secs)\\n(log scale)\",\n",
    "            width=50,\n",
    "            show_key=False,\n",
    "            border=False,\n",
    "        )\n",
    "    else:\n",
    "        chart = \"\"\n",
    "    return \"\\n\".join([\n",
    "        f\"timings recorded: {len(timed_answers)}\",\n",
    "        chart])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "cd2483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_question(q_id):\n",
    "    data = summarize_question(q_id)\n",
    "    question = data['question']\n",
    "    answer_counts = data['final_answers']\n",
    "    all_answers = answers_for_question(q_id, timed_only=False)\n",
    "    timed_answers = answers_for_question(q_id, timed_only=True)\n",
    "    if not answer_counts:\n",
    "        return \"(nothing recorded for this question)\"\n",
    "    full_summary = [\n",
    "#         textchart.add_border(f'Question {q_id}', fit=True, bold=True),\n",
    "        ''.join(data['question']['info']),\n",
    "#         f\"response validation used: {question['type']}\",\n",
    "#         \"CODINGS:\",\n",
    "#         \"\\n\".join([(v or '') for v in data['question']['options'].values()]),\n",
    "#         render_answer_frequency(answer_counts, all_answers),\n",
    "        timing_summary(timed_answers),\n",
    "    ]\n",
    "    return \"\\n\\n\".join(full_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "bb0faefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_cat_summary(cat):\n",
    "    return textchart.add_border(cat['label'], max_width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "7be5e070",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_question_ids = sorted(\n",
    "    set(\n",
    "        k[2] for k in _question_lookups \n",
    "        if k[2].startswith('v')\n",
    "    ), key=question_id_sort_fn\n",
    ")\n",
    "with open(f\"{DATA_FOLDER}/2022-09-11_timing_data.txt\", \"w\") as f:\n",
    "#     f.write(render_summary())\n",
    "    for cat in d1['coding'][6]['categories']:\n",
    "        entry = [render_cat_summary(cat)]\n",
    "        for q in cat['questions']:\n",
    "            q_id = q['id']\n",
    "            try:\n",
    "                entry.append(textchart.add_border(render_question(q_id)))\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "        f.write(textchart.add_border(\"\\n\".join(entry), max_width=93, bold=True))\n",
    "# with open(f\"{DATA_FOLDER}/2022-08-26_data.txt\", \"r\") as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "59e815d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────────────────────────────────────────────────────────────────────────────┐\r\n",
      "│                                                                                 │\r\n",
      "│ Fully Coded Policies: 113                                                       │\r\n",
      "│ Recorded Answers: 15344                                                         │\r\n",
      "│ Recorded Answers with Timing: 3043                                              │\r\n",
      "│                                                                                 │\r\n",
      "└─────────────────────────────────────────────────────────────────────────────────┘\r\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\r\n",
      "┃ CCPA                                                                                         ┃\r\n",
      "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\r\n"
     ]
    }
   ],
   "source": [
    "!head /home/stein/Dropbox/_Law/Documents_and_Administrata/_DATA/privacy_coding/2022-09-11_data.txt -n100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e5349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9552c93d",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "import csv\n",
    "\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "ES = Elasticsearch(\"http://localhost:9200\")\n",
    "INDEX_prefix = \"privacypolicy--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f383e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf19e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69779ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f2f753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023e3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fbb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26caef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b29830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08388e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c35eaff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\"* 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee70969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90850b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a8295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('documentcoding.com-v-KIfG3c')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "6791f50e02b0d468e77298a15b57239562bffc1394187b868314217441a851b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
